{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3moH1GaLaeW",
        "outputId": "263c4c59-bb8d-4771-bafa-00ea51fdff3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)\n",
        "\n",
        "# Some libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "#Load dataset\n",
        "input_file = np.load('/content/drive/My Drive/public_data.npz', allow_pickle=True)\n",
        "data = input_file['data']\n",
        "\n",
        "#Normalize data\n",
        "data = data / 255.0\n",
        "labels = input_file['labels']\n",
        "\n",
        "label_dict = {'unhealthy': 0, 'healthy': 1}\n",
        "labels = np.array([label_dict[label] for label in labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72NVqf98TelV",
        "outputId": "f4f99df2-58cf-46da-e66d-e580b382ecc2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to show images"
      ],
      "metadata": {
        "id": "HWQTwcKJT04G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(X_val, y_val):\n",
        "    num_img = 10\n",
        "    fig, axes = plt.subplots(1, num_img, figsize=(96, 96))\n",
        "\n",
        "    # Iterate through the selected number of images\n",
        "    for i in range(num_img):\n",
        "        ax = axes[i % num_img]\n",
        "        ax.imshow((X_val[i] / 255))  # Show the image\n",
        "        ax.set_title(f'{y_val[i][0]}')  # Show the corresponding digit label\n",
        "\n",
        "\n",
        "    # Adjust layout and display the images\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DJqMOujwTf_F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unrelevant data"
      ],
      "metadata": {
        "id": "pGQH85VtT4rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shrek_indices = []\n",
        "trol_indices = []\n",
        "new_data = []\n",
        "new_labels = []\n",
        "for i, image in enumerate(data):\n",
        "  if np.sum(data[506] - image) == 0:\n",
        "    shrek_indices.append(i)\n",
        "  elif np.sum(data[338] - image) == 0:\n",
        "    trol_indices.append(i)\n",
        "  else:\n",
        "    new_data.append(image)\n",
        "    new_labels.append(labels[i])\n",
        "\n",
        "data = np.array(new_data)\n",
        "labels = np.array(new_labels)"
      ],
      "metadata": {
        "id": "vyrR5OLCT6SN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pqtloyCZLbUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe38025-931e-44f5-e48e-c46bea793f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (3002, 96, 96, 3)\n",
            "X_test shape:  (2002, 96, 96, 3)\n",
            "y_train shape:  (3002, 1)\n",
            "y_test shape:  (2002, 1)\n",
            "Categorical label: [0. 1.]\n",
            "\"Default\" label: 1\n",
            "Epochs: 100\n",
            "Batch Size: 32\n",
            "Input Shape: (96, 96, 3)\n",
            "Output Shape: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#split into train and test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(data, labels, test_size=0.4, random_state=seed)\n",
        "\n",
        "labels = np.expand_dims(labels, axis=1)\n",
        "#split into train and validation\n",
        "y_train_val = np.expand_dims(y_train_val, axis=1)\n",
        "y_test = np.expand_dims(y_test, axis=1)\n",
        "\n",
        "labels = tfk.utils.to_categorical(labels)\n",
        "\n",
        "print(\"X_train shape: \", X_train_val.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "\n",
        "print(\"y_train shape: \", y_train_val.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n",
        "\n",
        "# Show the first 10 images\n",
        "#show_images(X_train_val, y_train_val)\n",
        "\n",
        "\n",
        "#Counting occurrences of target classes:')\n",
        "#print(pd.DataFrame(y_train_val, columns=['digit'])['digit'].value_counts())\n",
        "\n",
        "\n",
        "y_train_val = tfk.utils.to_categorical(y_train_val)\n",
        "y_test = tfk.utils.to_categorical(y_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Compare categorical label and \"default\" label representation\n",
        "print('Categorical label:', y_train[0])           # Display the categorical label\n",
        "print('\"Default\" label:', np.argmax(y_train[0]))   # Display the equivalent numeric label\n",
        "\n",
        "\n",
        "# Define key model parameters\n",
        "input_shape = X_train.shape[1:]  # Input shape for the model\n",
        "output_shape = y_train.shape[1]  # Output shape for the model\n",
        "batch_size = 32               # Batch size for training\n",
        "epochs = 100                   # Number of training epochs\n",
        "\n",
        "# Print the defined parameters\n",
        "print(\"Epochs:\", epochs)\n",
        "print(\"Batch Size:\", batch_size)\n",
        "print(\"Input Shape:\", input_shape)\n",
        "print(\"Output Shape:\", output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildCNN(input_shape, output_shape):\n",
        "    # Define the model\n",
        "    preprocessing = tf.keras.Sequential([\n",
        "        tfkl.RandomFlip(\"horizontal\"),\n",
        "        tfkl.RandomRotation(0.2),\n",
        "        tfkl.RandomBrightness(0.2, value_range=(0,1)),\n",
        "        tfkl.RandomTranslation(0.2,0.2),\n",
        "    ], name='preprocessing')\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape)\n",
        "    x = preprocessing(input_layer)\n",
        "    x = tfkl.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv_1')(x)\n",
        "    x = tfkl.MaxPooling2D(pool_size=(2, 2), name='pool_1')(x)\n",
        "    x = tfkl.Dropout(0.25, name='dropout1')(x)\n",
        "    x = tfkl.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv_2')(x)\n",
        "    x = tfkl.MaxPooling2D(pool_size=(2, 2), name='pool_2')(x)\n",
        "    x = tfkl.Dropout(0.25, name='dropout2')(x)\n",
        "    x = tfkl.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv_3')(x)\n",
        "    x = tfkl.MaxPooling2D(pool_size=(2, 2), name='pool_3')(x)\n",
        "    x = tfkl.Dropout(0.25, name='dropout3')(x)\n",
        "    x = tfkl.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv_4')(x)\n",
        "    x = tfkl.MaxPooling2D(pool_size=(2, 2), name='pool_4')(x)\n",
        "    x = tfkl.Dropout(0.25, name='dropout4')(x)\n",
        "    x = tfkl.Flatten(name='flatten')(x)\n",
        "    x = tfkl.Dense(256, activation='relu', name='dense_1')(x)\n",
        "    x = tfkl.Dense(64, activation='relu', name='dense_2')(x)\n",
        "    output_layer = tfkl.Dense(output_shape, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "DKkqol3YTEjb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "YFRYly78bNhH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = tfk.callbacks.ModelCheckpoint('best_model_finetune.h5', monitor='val_accuracy', save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "weTRI_MibO6R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "#class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights_dict = {0: 0.81, 1: 1.29} #precomputed\n",
        "\n",
        "print(f\"Class weights: {class_weights_dict}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBlkPwJnbXNf",
        "outputId": "1fcecbb7-652c-435d-f423-a7e0051d303e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: 0.81, 1: 1.29}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 50:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "lrscheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "4wyy80BybZiM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = buildCNN(input_shape, output_shape)\n",
        "cnn_model.summary()\n",
        "\n",
        "history = cnn_model.fit(X_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        callbacks=[early_stopping, model_checkpoint, lrscheduler],\n",
        "                        validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "jb_DvmiwTCDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
