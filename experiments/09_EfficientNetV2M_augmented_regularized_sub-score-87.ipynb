{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6882583,"sourceType":"datasetVersion","datasetId":3954337},{"sourceId":6883491,"sourceType":"datasetVersion","datasetId":3954820},{"sourceId":6891939,"sourceType":"datasetVersion","datasetId":3959198},{"sourceId":6933400,"sourceType":"datasetVersion","datasetId":3981155},{"sourceId":6945757,"sourceType":"datasetVersion","datasetId":3989030}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fix randomness and hide warnings\nseed = 42\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\nimport numpy as np\nnp.random.seed(seed)\n\nimport logging\n\nimport random\nrandom.seed(seed)\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom keras import layers as tfkl\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(tf.__version__)\n\n# Some libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport seaborn as sns\n\ninput_file = np.load('public_data.npz', allow_pickle=True)\ndata = input_file['data']\n\nlabels = input_file['labels']\n\nlabel_dict = {'healthy': 0, 'unhealthy': 1}\nlabels = np.array([label_dict[label] for label in labels])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPb-oepWMoel","outputId":"a59a035e-f3b0-46be-cc49-dab1c766ab26"},"execution_count":1,"outputs":[{"name":"stdout","output_type":"stream","text":"2.14.0\n"}]},{"cell_type":"markdown","source":"## Preprocess input.","metadata":{}},{"cell_type":"code","source":"#data = data/255.0\n\nfrom keras.applications.efficientnet_v2 import preprocess_input\ndata = preprocess_input(data)","metadata":{"id":"iyW8ZLuF7snN"},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Remove outliers.","metadata":{}},{"cell_type":"code","source":"shrek_indices = []\ntrol_indices = []\nnew_data = []\nnew_labels = []\nfor i, image in enumerate(data):\n  if np.sum(data[506] - image) == 0:\n    shrek_indices.append(i)\n  elif np.sum(data[338] - image) == 0:\n    trol_indices.append(i)\n  else:\n    new_data.append(image)\n    new_labels.append(labels[i])\n\nimages = np.array(new_data)\nlabels = np.array(new_labels)","metadata":{"id":"K-INeLsUTutg"},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Split the dataset into train and validation sets.","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.1, stratify=labels, random_state=seed)","metadata":{"id":"2s7QHqECMsxi"},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]  # Input shape for the model","metadata":{"id":"_cC_ZrfJNO1V"},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load base model Efficient Net.","metadata":{}},{"cell_type":"code","source":"learned_model = tfk.applications.EfficientNetV2M(\n    input_shape=(96, 96, 3),\n    include_top=False,\n    weights=\"imagenet\",\n    pooling='max',\n)","metadata":{"id":"Nh9o9JVcNRWF"},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"learned_model.trainable = True","metadata":{"id":"0WSPyd2hPcnp"},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Freeze the first 85 layers.","metadata":{}},{"cell_type":"code","source":"N = 85\nfor i, layer in enumerate(learned_model.layers[:N]):\n  layer.trainable=False","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcnVUT-5Pbz8","outputId":"8aa9824d-1bf5-49f4-a141-e07d230ddac3"},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Apply data augmentation.","metadata":{}},{"cell_type":"code","source":"preprocessing = tf.keras.Sequential([\n    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n    tfkl.RandomRotation(0.9),\n    tfkl.GaussianNoise(0.3),\n    tfkl.RandomContrast(0.4),\n    tfkl.RandomBrightness(0.4),\n], name='preprocessing')\n\n\ninput_layer = tfkl.Input(shape=input_shape)\nx = preprocessing(input_layer)","metadata":{"id":"vRul5dEJNuHr"},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"x = learned_model(x)","metadata":{"id":"rq05G8FoO2f5"},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Add custom layers to the base model.","metadata":{}},{"cell_type":"code","source":"from keras import regularizers\n\nx = tfkl.Flatten(name='flattenLast')(x)\nx = tfkl.Dropout(0.2)(x)\nx = tfkl.Dense(512, activation='relu', name='Dense_1', kernel_regularizer=regularizers.l1_l2(0.01))(x)\nx = tfkl.Dropout(0.2)(x)\nx = tfkl.Dense(256, activation='relu', name='Dense_2', kernel_regularizer=regularizers.l1_l2(0.01))(x)\nx = tfkl.Dropout(0.2)(x)\nx = tfkl.Dense(128, activation='relu', name='Dense_3', kernel_regularizer=regularizers.l1_l2(0.01))(x)\nx = tfkl.Dropout(0.2)(x)\nx = tfkl.Dense(64, activation='relu', name='Dense_4', kernel_regularizer=regularizers.l1_l2(0.01))(x)\nx = tfkl.Dropout(0.2)(x)\nx = tfkl.Dense(16, activation='relu', name='Dense_5', kernel_regularizer=regularizers.l1_l2(0.01))(x)\nx = tfkl.Dropout(0.2)(x)\noutput_layer = tfkl.Dense(1, activation='sigmoid', name='output')(x)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)","metadata":{"id":"Bn4-w2C9PMb9"},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-5), metrics='accuracy')\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFkokwZ1PN-X","outputId":"9e2ec129-61f4-47fe-87a1-8975dcad2edf"},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"model\"\n\n_________________________________________________________________\n\n Layer (type)                Output Shape              Param #   \n\n=================================================================\n\n input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n\n                                                                 \n\n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n\n                                                                 \n\n efficientnetv2-m (Function  (None, 1280)              53150388  \n\n al)                                                             \n\n                                                                 \n\n flattenLast (Flatten)       (None, 1280)              0         \n\n                                                                 \n\n dropout (Dropout)           (None, 1280)              0         \n\n                                                                 \n\n Dense_1 (Dense)             (None, 512)               655872    \n\n                                                                 \n\n dropout_1 (Dropout)         (None, 512)               0         \n\n                                                                 \n\n Dense_2 (Dense)             (None, 256)               131328    \n\n                                                                 \n\n dropout_2 (Dropout)         (None, 256)               0         \n\n                                                                 \n\n Dense_3 (Dense)             (None, 128)               32896     \n\n                                                                 \n\n dropout_3 (Dropout)         (None, 128)               0         \n\n                                                                 \n\n Dense_4 (Dense)             (None, 64)                8256      \n\n                                                                 \n\n dropout_4 (Dropout)         (None, 64)                0         \n\n                                                                 \n\n Dense_5 (Dense)             (None, 16)                1040      \n\n                                                                 \n\n dropout_5 (Dropout)         (None, 16)                0         \n\n                                                                 \n\n output (Dense)              (None, 1)                 17        \n\n                                                                 \n\n=================================================================\n\nTotal params: 53979797 (205.92 MB)\n\nTrainable params: 52149133 (198.93 MB)\n\nNon-trainable params: 1830664 (6.98 MB)\n\n_________________________________________________________________\n"}]},{"cell_type":"markdown","source":"## Set the callbacks.","metadata":{}},{"cell_type":"code","source":"early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='min', restore_best_weights=True)","metadata":{"id":"Qyv-LU3fUB2g"},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = tfk.callbacks.ModelCheckpoint('best_model_finetune.h5', monitor='val_accuracy', save_best_only=True, mode='max')","metadata":{"id":"tN286d7yToOc"},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n#class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n#class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\nclass_weights_dict = {0: 0.81, 1: 1.29}\n\nprint(f\"Class weights: {class_weights_dict}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVanTcK3UMRR","outputId":"b0f7ea9a-38b1-412b-ee9d-f06c670f9b1e"},"execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"Class weights: {0: 0.81, 1: 1.29}\n"}]},{"cell_type":"markdown","source":"## Fit the model.","metadata":{}},{"cell_type":"code","source":"batch_size=32\nepochs=30\nhistory = model.fit(\n    x=X_train,\n    y=y_train,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_data=(X_val, y_val),\n    class_weight=class_weights_dict,\n    callbacks=[model_checkpoint],\n    verbose=1\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWNqMePaUdoz","outputId":"2b3273f8-595b-4962-f86e-c9314a626e1c"},"execution_count":16,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/30\n\n141/141 [==============================] - 124s 240ms/step - loss: 285.8959 - accuracy: 0.4302 - val_loss: 280.3513 - val_accuracy: 0.4232\n\nEpoch 2/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 275.1396 - accuracy: 0.4468 - val_loss: 269.6559 - val_accuracy: 0.4850\n\nEpoch 3/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 264.4569 - accuracy: 0.4619 - val_loss: 259.0540 - val_accuracy: 0.5250\n\nEpoch 4/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 253.8908 - accuracy: 0.4695 - val_loss: 248.5713 - val_accuracy: 0.5070\n\nEpoch 5/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 243.4644 - accuracy: 0.4699 - val_loss: 238.2341 - val_accuracy: 0.5150\n\nEpoch 6/30\n\n141/141 [==============================] - 29s 205ms/step - loss: 233.1954 - accuracy: 0.4737 - val_loss: 228.0535 - val_accuracy: 0.5449\n\nEpoch 7/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 223.0988 - accuracy: 0.4783 - val_loss: 218.0535 - val_accuracy: 0.5529\n\nEpoch 8/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 213.1779 - accuracy: 0.4908 - val_loss: 208.2380 - val_accuracy: 0.5868\n\nEpoch 9/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 203.4541 - accuracy: 0.4890 - val_loss: 198.6145 - val_accuracy: 0.5968\n\nEpoch 10/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 193.9334 - accuracy: 0.5265 - val_loss: 189.1920 - val_accuracy: 0.6926\n\nEpoch 11/30\n\n141/141 [==============================] - 29s 208ms/step - loss: 184.6248 - accuracy: 0.5601 - val_loss: 179.9936 - val_accuracy: 0.7405\n\nEpoch 12/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 175.5441 - accuracy: 0.6131 - val_loss: 171.0349 - val_accuracy: 0.7605\n\nEpoch 13/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 166.6973 - accuracy: 0.6485 - val_loss: 162.3098 - val_accuracy: 0.8024\n\nEpoch 14/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 158.0956 - accuracy: 0.6802 - val_loss: 153.8195 - val_accuracy: 0.8244\n\nEpoch 15/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 149.7326 - accuracy: 0.7018 - val_loss: 145.5683 - val_accuracy: 0.8283\n\nEpoch 16/30\n\n141/141 [==============================] - 29s 205ms/step - loss: 141.6152 - accuracy: 0.7202 - val_loss: 137.5659 - val_accuracy: 0.8383\n\nEpoch 17/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 133.7357 - accuracy: 0.7457 - val_loss: 129.8148 - val_accuracy: 0.8303\n\nEpoch 18/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 126.1129 - accuracy: 0.7606 - val_loss: 122.3229 - val_accuracy: 0.8303\n\nEpoch 19/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 118.7492 - accuracy: 0.7590 - val_loss: 115.0603 - val_accuracy: 0.8283\n\nEpoch 20/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 111.6334 - accuracy: 0.7730 - val_loss: 108.0630 - val_accuracy: 0.8483\n\nEpoch 21/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 104.7825 - accuracy: 0.7777 - val_loss: 101.3339 - val_accuracy: 0.8483\n\nEpoch 22/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 98.1863 - accuracy: 0.7919 - val_loss: 94.8676 - val_accuracy: 0.8443\n\nEpoch 23/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 91.8551 - accuracy: 0.7957 - val_loss: 88.6641 - val_accuracy: 0.8463\n\nEpoch 24/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 85.7822 - accuracy: 0.8059 - val_loss: 82.7315 - val_accuracy: 0.8363\n\nEpoch 25/30\n\n141/141 [==============================] - 29s 205ms/step - loss: 79.9773 - accuracy: 0.8112 - val_loss: 77.0599 - val_accuracy: 0.8543\n\nEpoch 26/30\n\n141/141 [==============================] - 23s 163ms/step - loss: 74.4277 - accuracy: 0.8201 - val_loss: 71.6370 - val_accuracy: 0.8543\n\nEpoch 27/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 69.1404 - accuracy: 0.8201 - val_loss: 66.4778 - val_accuracy: 0.8603\n\nEpoch 28/30\n\n141/141 [==============================] - 23s 164ms/step - loss: 64.1102 - accuracy: 0.8286 - val_loss: 61.5805 - val_accuracy: 0.8583\n\nEpoch 29/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 59.3428 - accuracy: 0.8310 - val_loss: 56.9452 - val_accuracy: 0.8623\n\nEpoch 30/30\n\n141/141 [==============================] - 29s 204ms/step - loss: 54.8377 - accuracy: 0.8301 - val_loss: 52.5699 - val_accuracy: 0.8703\n"}]},{"cell_type":"code","source":"batch_size=16\nepochs=10\nhistory = model.fit(\n    x=X_train,\n    y=y_train,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_data=(X_val, y_val),\n    class_weight=class_weights_dict,\n    callbacks=[model_checkpoint],\n    verbose=1\n)","metadata":{},"execution_count":23,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/10\n\n282/282 [==============================] - 36s 127ms/step - loss: 0.8920 - accuracy: 0.9132 - val_loss: 0.8961 - val_accuracy: 0.9082\n\nEpoch 2/10\n\n282/282 [==============================] - 42s 148ms/step - loss: 0.8754 - accuracy: 0.9147 - val_loss: 0.8795 - val_accuracy: 0.9182\n\nEpoch 3/10\n\n282/282 [==============================] - 36s 128ms/step - loss: 0.8510 - accuracy: 0.9181 - val_loss: 0.8700 - val_accuracy: 0.9042\n\nEpoch 4/10\n\n282/282 [==============================] - 42s 147ms/step - loss: 0.8419 - accuracy: 0.9183 - val_loss: 0.8464 - val_accuracy: 0.9202\n\nEpoch 5/10\n\n282/282 [==============================] - 36s 127ms/step - loss: 0.8231 - accuracy: 0.9212 - val_loss: 0.8359 - val_accuracy: 0.9102\n\nEpoch 6/10\n\n282/282 [==============================] - 42s 147ms/step - loss: 0.8146 - accuracy: 0.9223 - val_loss: 0.8219 - val_accuracy: 0.9242\n\nEpoch 7/10\n\n282/282 [==============================] - 36s 127ms/step - loss: 0.8024 - accuracy: 0.9236 - val_loss: 0.8160 - val_accuracy: 0.8982\n\nEpoch 8/10\n\n282/282 [==============================] - 36s 126ms/step - loss: 0.7977 - accuracy: 0.9167 - val_loss: 0.7984 - val_accuracy: 0.9162\n\nEpoch 9/10\n\n282/282 [==============================] - 36s 126ms/step - loss: 0.7894 - accuracy: 0.9141 - val_loss: 0.7959 - val_accuracy: 0.9042\n\nEpoch 10/10\n\n282/282 [==============================] - 36s 126ms/step - loss: 0.7721 - accuracy: 0.9165 - val_loss: 0.7762 - val_accuracy: 0.9142\n"}]},{"cell_type":"markdown","source":"## Evaluate on training set.","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the training set\nmodel.load_weights(\"best_model_finetune.h5\")\ntest_loss, test_accuracy = model.evaluate(X_train, y_train, verbose=1)\n\nprint(\"Test loss:\", test_loss)\nprint(\"Test accuracy:\", test_accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98z5FdMNapF3","outputId":"390f483f-af9d-4b59-e81c-52782bc1e7aa"},"execution_count":26,"outputs":[{"name":"stdout","output_type":"stream","text":"141/141 [==============================] - 7s 51ms/step - loss: 0.7730 - accuracy: 0.9607\n\nTest loss: 0.7730275988578796\n\nTest accuracy: 0.9606928825378418\n"}]},{"cell_type":"markdown","source":"## Evaluate on validation set.","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the validation set\n#model.load_weights(\"best_model.h5\")\ntest_loss, test_accuracy = model.evaluate(X_val, y_val, verbose=1)\n\nprint(\"Test loss:\", test_loss)\nprint(\"Test accuracy:\", test_accuracy)","metadata":{},"execution_count":27,"outputs":[{"name":"stdout","output_type":"stream","text":"16/16 [==============================] - 1s 51ms/step - loss: 0.8219 - accuracy: 0.9242\n\nTest loss: 0.8219051361083984\n\nTest accuracy: 0.9241517186164856\n"}]},{"cell_type":"code","source":"model.save('saved_model')","metadata":{"id":"nPHU6ljLsenc"},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"best_model.h5\")","metadata":{},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"batch_size=16\nepochs=10\nmodel.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(1e-6), metrics='accuracy')\nhistory = model.fit(\n    x=X_val,\n    y=y_val,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_data=(X_train, y_train),\n    class_weight=class_weights_dict,\n    verbose=1\n)","metadata":{},"execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/10\n\n32/32 [==============================] - 84s 524ms/step - loss: 0.6000 - accuracy: 0.8683 - val_loss: 0.1227 - val_accuracy: 0.9920\n\nEpoch 2/10\n\n32/32 [==============================] - 12s 376ms/step - loss: 0.5436 - accuracy: 0.8723 - val_loss: 0.1217 - val_accuracy: 0.9927\n\nEpoch 3/10\n\n32/32 [==============================] - 12s 378ms/step - loss: 0.5823 - accuracy: 0.8663 - val_loss: 0.1236 - val_accuracy: 0.9927\n\nEpoch 4/10\n\n32/32 [==============================] - 12s 380ms/step - loss: 0.5440 - accuracy: 0.8623 - val_loss: 0.1226 - val_accuracy: 0.9927\n\nEpoch 5/10\n\n32/32 [==============================] - 12s 377ms/step - loss: 0.4978 - accuracy: 0.8782 - val_loss: 0.1263 - val_accuracy: 0.9911\n\nEpoch 6/10\n\n32/32 [==============================] - 12s 378ms/step - loss: 0.4350 - accuracy: 0.8982 - val_loss: 0.1205 - val_accuracy: 0.9929\n\nEpoch 7/10\n\n32/32 [==============================] - 12s 378ms/step - loss: 0.4999 - accuracy: 0.8643 - val_loss: 0.1286 - val_accuracy: 0.9902\n\nEpoch 8/10\n\n32/32 [==============================] - 12s 379ms/step - loss: 0.4785 - accuracy: 0.8822 - val_loss: 0.1228 - val_accuracy: 0.9922\n\nEpoch 9/10\n\n32/32 [==============================] - 12s 378ms/step - loss: 0.6316 - accuracy: 0.8603 - val_loss: 0.1233 - val_accuracy: 0.9918\n\nEpoch 10/10\n\n32/32 [==============================] - 12s 380ms/step - loss: 0.3853 - accuracy: 0.8743 - val_loss: 0.1268 - val_accuracy: 0.9913\n"}]},{"cell_type":"code","source":"model.save_weights(\"96-97_acc.h5\")","metadata":{},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.save(\"saved_model\")","metadata":{},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Work on new model with embeddings.","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\n\nintermediate_layer = model.get_layer('flattenLast')\n\n# Create a new model with the selected intermediate layer as the output\nnew_model = Model(inputs=model.input, outputs=intermediate_layer.output)\n\n# Get the embeddings for the example image\nembeddings = new_model(X_train[:1])\n\nprint(\"Embeddings shape:\", embeddings.shape)","metadata":{},"execution_count":33,"outputs":[{"name":"stdout","output_type":"stream","text":"Embeddings shape: (1, 1280)\n"}]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\ncosine_sim_matrix = cosine_similarity(new_model(X_train[:3]), new_model(X_train[3:4]))\ncosine_sim_matrix","metadata":{},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":["array([[0.9210138 ],\n","       [0.9158238 ],\n","       [0.92049253]], dtype=float32)"]},"metadata":{}}]},{"cell_type":"code","source":"embeddings = new_model(images)\n\n# Step 3: Calculate Cosine Similarity\nsimilarity_matrix = cosine_similarity(embeddings)","metadata":{},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":["array([[ 1.0000001 ,  0.884811  ,  0.84379697, ..., -0.5961801 ,\n","         0.79545754,  0.8370678 ],\n","       [ 0.884811  ,  1.0000004 ,  0.95030785, ..., -0.38202488,\n","         0.9380702 ,  0.92915016],\n","       [ 0.84379697,  0.95030785,  1.0000002 , ..., -0.28425545,\n","         0.9600454 ,  0.9284129 ],\n","       ...,\n","       [-0.5961801 , -0.38202488, -0.28425545, ...,  1.        ,\n","        -0.20630479, -0.33521122],\n","       [ 0.79545754,  0.9380702 ,  0.9600454 , ..., -0.20630479,\n","         1.0000001 ,  0.9270675 ],\n","       [ 0.8370678 ,  0.92915016,  0.9284129 , ..., -0.33521122,\n","         0.9270675 ,  0.9999999 ]], dtype=float32)"]},"metadata":{}}]},{"cell_type":"code","source":"probs = model.predict(images)","metadata":{},"execution_count":60,"outputs":[{"name":"stdout","output_type":"stream","text":"157/157 [==============================] - 8s 48ms/step\n"}]},{"cell_type":"code","source":"probs[:,0].shape","metadata":{},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":["(5004,)"]},"metadata":{}}]},{"cell_type":"code","source":"sorted_indices = np.argsort(-probs[:,0])","metadata":{},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"probs[sorted_indices[:10]]","metadata":{},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":["array([[0.99034846],\n","       [0.9879616 ],\n","       [0.9867209 ],\n","       [0.98564816],\n","       [0.9852684 ],\n","       [0.98370355],\n","       [0.9834063 ],\n","       [0.9821669 ],\n","       [0.9819166 ],\n","       [0.98140407]], dtype=float32)"]},"metadata":{}}]},{"cell_type":"code","source":"sorted_indices[:10]","metadata":{},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":["array([ 804, 2291, 2940, 2739,  209,   96,  423, 3350, 3836, 2734])"]},"metadata":{}}]},{"cell_type":"code","source":"predictions = [1 if pred > 0.5 else 0 for pred in predictions]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mislabeled_indices = np.where((predictions != labels) & (labels == 1))[0]","metadata":{},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"mislabeled_imgs = images[mislabeled_indices]","metadata":{},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"msl_predictions = new_model(mislabeled_imgs)","metadata":{},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"dist_embeddings = new_model(images[sorted_indices[:10]])","metadata":{},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"sim_m = cosine_similarity(msl_predictions, dist_embeddings)","metadata":{},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"sim_m.shape","metadata":{},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":["(151, 10)"]},"metadata":{}}]},{"cell_type":"code","source":"for sim in sim_m:\n    print(np.max(sim))","metadata":{},"execution_count":92,"outputs":[{"name":"stdout","output_type":"stream","text":"0.9807346\n\n0.96228737\n\n0.9423652\n\n0.99145913\n\n0.9948994\n\n0.99623567\n\n0.9845739\n\n0.94965637\n\n0.98275465\n\n0.97669923\n\n0.93783194\n\n0.9158164\n\n0.91619456\n\n0.928523\n\n0.99519205\n\n0.9948138\n\n0.9923296\n\n0.9918233\n\n0.9895495\n\n0.9444544\n\n0.9237901\n\n0.9669758\n\n0.94057655\n\n0.95045507\n\n0.9883579\n\n0.9959743\n\n0.9915093\n\n0.6564909\n\n0.9800378\n\n0.9554721\n\n0.9706751\n\n0.9870877\n\n0.9940381\n\n0.80235994\n\n0.587065\n\n0.3121146\n\n0.9646051\n\n0.7997391\n\n0.99345064\n\n0.9941846\n\n0.923667\n\n0.9605049\n\n0.9534553\n\n0.95862633\n\n0.5778718\n\n0.9774114\n\n0.9311223\n\n0.9336894\n\n0.9886695\n\n0.99656165\n\n0.85372055\n\n0.91917145\n\n0.95877135\n\n0.9660882\n\n0.9931451\n\n0.99248946\n\n0.9962543\n\n0.8905393\n\n0.9918245\n\n0.9936083\n\n0.44616234\n\n0.9437507\n\n0.9798285\n\n0.90647894\n\n0.9614972\n\n0.5294775\n\n0.9914633\n\n0.938882\n\n0.94660854\n\n0.89864135\n\n0.99053776\n\n0.5944795\n\n0.95937335\n\n0.94885933\n\n0.9723991\n\n0.9492033\n\n0.97186923\n\n0.9448581\n\n0.9951218\n\n0.9945717\n\n0.991589\n\n0.9543682\n\n0.99386996\n\n0.9954542\n\n0.95208156\n\n0.9624305\n\n0.99160886\n\n0.9704664\n\n0.99054736\n\n0.8164587\n\n0.9673587\n\n0.9612248\n\n0.9912182\n\n0.9114741\n\n0.7568513\n\n0.98157084\n\n0.6950026\n\n0.9420578\n\n0.9914843\n\n0.9930672\n\n0.89766264\n\n0.99014354\n\n0.9958967\n\n0.8961363\n\n0.5057822\n\n0.8453641\n\n0.7936729\n\n0.99308914\n\n0.72695756\n\n0.97717613\n\n0.99462515\n\n0.9802415\n\n0.96177423\n\n0.9812113\n\n0.9514357\n\n0.8777991\n\n0.95921874\n\n0.9509872\n\n0.7628186\n\n0.9946803\n\n0.97413754\n\n0.99283737\n\n0.81372434\n\n0.9962764\n\n0.8864713\n\n0.69268566\n\n0.86274755\n\n0.80815864\n\n0.3479543\n\n0.5156007\n\n0.9641053\n\n0.75548136\n\n0.9526546\n\n0.9133835\n\n0.8373492\n\n0.99538934\n\n0.45599902\n\n0.9607242\n\n0.8765248\n\n0.8990685\n\n0.71629673\n\n0.9602477\n\n0.9822507\n\n0.992848\n\n0.95525724\n\n0.99507695\n\n0.9865587\n\n0.6583512\n\n0.31265578\n\n0.94822097\n\n0.95426315\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}